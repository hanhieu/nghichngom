{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.nldc.evn.vn/api/services/app/Pages/GetChartNguonDien'\n",
    "# #get data from url\n",
    "# response = requests.get(url)\n",
    "# #convert data to json\n",
    "# data = response.json()\n",
    "# #convert data to pandas dataframe\n",
    "# df = pd.DataFrame(data['result']['data']['nguonDiens'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCS = pd.DataFrame()\n",
    "def get_SCS(i):\n",
    "    url = 'https://ecargo.scsc.vn/General/Tonnage/Public'\n",
    "    payload = {'year':i}\n",
    "    response = requests.post(url, data=payload)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "for i in range(2017,2025):\n",
    "    x = get_SCS(i)\n",
    "    SCS = pd.concat([SCS,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCS.to_excel('C:/Users/HP PAVILION/Desktop/data/IR/IR/SCS/SCS.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TLG_VI(x):\n",
    "    response = requests.get(x)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    titles = []\n",
    "    pdfs = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if 'nhà đầu tư' in link.text.lower():\n",
    "            titles.append(link.text)\n",
    "            if link.get('href').endswith('.pdf'):\n",
    "                pdfs.append(link.get('href'))\n",
    "    #create a dataframe from titles and pdfs\n",
    "    df = pd.DataFrame({'Title':titles, 'PDF':pdfs})\n",
    "    return df\n",
    "\n",
    "def get_TLG_EN(x):\n",
    "    response = requests.get(x)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    titles = []\n",
    "    pdfs = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if 'newsletter' in link.text.lower():\n",
    "            titles.append(link.text)\n",
    "            if link.get('href').endswith('.pdf'):\n",
    "                pdfs.append(link.get('href'))\n",
    "    #create a dataframe from titles and pdfs\n",
    "    df = pd.DataFrame({'Title':titles, 'PDF':pdfs})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLG_VI = pd.DataFrame()\n",
    "TLG_EN = pd.DataFrame()\n",
    "for i in range(1,19):\n",
    "    url_VI = 'https://thienlonggroup.com/quan-he-co-dong/tai-lieu-khac?page='+str(i)\n",
    "    url_EN = 'https://thienlonggroup.com/en/quan-he-co-dong/tai-lieu-khac?page='+str(i)\n",
    "    #use get_TLG function to get data from url and append to dataframe TLG\n",
    "    x = get_TLG_VI(url_VI)\n",
    "    y = get_TLG_EN(url_EN)\n",
    "    TLG_VI = pd.concat([TLG_VI,x])\n",
    "    TLG_EN = pd.concat([TLG_EN,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP PAVILION\\Desktop\n"
     ]
    }
   ],
   "source": [
    "#get desktop dir\n",
    "desktop_path = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "print(desktop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\HP PAVILION\\\\DesktopIR/TLG/VI/Bản tin dành cho Nhà đầu tư Tháng 2 2024.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(TLG_VI)):\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(TLG_VI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPDF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i])\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdesktop_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIR/TLG/VI/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mTLG_VI\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# for i in range(len(TLG_EN)):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     response = requests.get(TLG_EN['PDF'].iloc[i])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     with open(desktop_path+'IR/TLG/EN/'+TLG_VI['Title'].iloc[i]+'.pdf', 'wb') as f:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#         f.write(response.content)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\HP PAVILION\\\\DesktopIR/TLG/VI/Bản tin dành cho Nhà đầu tư Tháng 2 2024.pdf'"
     ]
    }
   ],
   "source": [
    "#save pdf from PDF to C:/Users/hoang.nguyennhat/Desktop/IR/TLG with Title as file name\n",
    "for i in range(len(TLG_VI)):\n",
    "    response = requests.get(TLG_VI['PDF'].iloc[i])\n",
    "    with open(desktop_path+'/IR/TLG/VI/'+TLG_VI['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "for i in range(len(TLG_EN)):\n",
    "    response = requests.get(TLG_EN['PDF'].iloc[i])\n",
    "    with open(desktop_path+'/IR/TLG/EN/'+TLG_VI['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the filename from C:/Users/hoang.nguyennhat/Desktop/IR/TLG/EN/\n",
    "import os\n",
    "files = os.listdir('C:/Users/hoang.nguyennhat/Desktop/IR/TLG/EN/')\n",
    "#select the string before - of the filename, remove blank space\n",
    "a = [x.split('-')[0].strip() for x in files]\n",
    "#remove .pdf from the string\n",
    "a = [x.replace('.pdf','') for x in a]\n",
    "#convert files to format YYYY-mm, for example 'August 2021' to '2021-08'\n",
    "a = [pd.to_datetime(x).strftime('%Y-%m') for x in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename('C:/Users/hoang.nguyennhat/Desktop/IR/TLG/EN/'+files[i],'C:/Users/hoang.nguyennhat/Desktop/IR/TLG/EN/'+a[i]+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. HDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = []\n",
    "list_file = []\n",
    "url = 'https://hado.com.vn/Ajax/Home/LoadContentShareHolders'\n",
    "def get_id_HDG(i):\n",
    "    data = {'p': i,'id': 19}\n",
    "    response = requests.post(url, data=data)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find table in soup\n",
    "    table = soup.find('table')\n",
    "    #convert table to dataframe\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    #find javascript void in soup\n",
    "    for link in soup.find_all('a'):\n",
    "        #select the string include void and get the number in the ()\n",
    "        if 'javascript:void' in link.get('href'):\n",
    "            \n",
    "        #add it into list_id\n",
    "            list_id.append(link.get('href').split('(')[1].split(')')[0])\n",
    "            list_file.append(link.text)\n",
    "        #create the dataframe from list_id and list_file\n",
    "    df = pd.DataFrame({'ID':list_id, 'File':list_file})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_HDG(id):\n",
    "    url = 'https://hado.com.vn/Ajax/Content/ViewDetail?id='+str(id)\n",
    "    base_url = 'https://hado.com.vn'\n",
    "    response = requests.get(url)\n",
    "    #response json\n",
    "    data = response.json()\n",
    "    #find href in data\n",
    "    soup = BeautifulSoup(data['content'], 'html.parser')\n",
    "    #find all href\n",
    "    for link in soup.find_all('a'):\n",
    "        a = (base_url+link.get('href'))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    x = get_id_HDG(i)\n",
    "    df = pd.concat([df,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PDF'] = df['ID'].apply(get_pdf_HDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://hado.com.vn/Uploads/files/BAN%20TIN%20IR%20QUY%201%202024%20(1).pdf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang.nguyennhat\\AppData\\Local\\Temp\\ipykernel_29068\\485858271.py:6: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(len(df)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2870eb4fdd7249bb9d291c3f7a963f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use tnrange to create progress bar\n",
    "from tqdm import tnrange\n",
    "#replace / with - in File\n",
    "df['File'] = df['File'].str.replace('/','-')\n",
    "#save pdf to C:/Users/hoang.nguyennhat/Desktop/IR/HDG\n",
    "for i in tnrange(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open('C:/Users/hoang.nguyennhat/Desktop/IR/HDG/'+str(df['File'].iloc[i])+'.pdf', 'wb') as f:\n",
    "        f.write(response.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#get the path of desktop from os\n",
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#get files from desktop/data/IR\n",
    "files = os.listdir(desktop+'/data/IR/IR/HDG/')\n",
    "#get the string after tư\n",
    "a = [x.split('tư')[1].strip() for x in files]\n",
    "a = [x.lower().replace('tháng ','T').replace('quý ','Q').strip() for x in a]\n",
    "#get the string after - and before .pdf in a and change it to the beginning of the string\n",
    "a = [x.split('-')[1].replace('.pdf','')+'-'+x.split('-')[0]+'-HDG.pdf' for x in a]\n",
    "a = [x.replace('Qi-','Q1-').replace('Qii-','Q2-').replace('Qiii-','Q3-').replace('Qiv-','Q4-') for x in a]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/HDG/'+files[i],desktop+'/data/IR/IR/HDG/'+a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PGV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.genco3.com'\n",
    "def get_pdf_PGV(x):\n",
    "    response = requests.get(x)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    list_file = []\n",
    "    list_name = []\n",
    "    #file all div class = 'file' in soup\n",
    "    for link in soup.find_all('div', class_='sn-new-item'):\n",
    "    #find p class = 'title'\n",
    "        name = link.find('p', class_='title').text\n",
    "        #beautify the name\n",
    "        name = name.replace('\\n','').strip()\n",
    "        list_name.append(name)\n",
    "        #get pdf link from a tag\n",
    "        pdf = link.find('a').get('href')\n",
    "        pdf = base_url+pdf\n",
    "        list_file.append(pdf)\n",
    "    #convert list_name and list_file to dataframe\n",
    "    df = pd.DataFrame({'Name':list_name, 'PDF':list_file})\n",
    "    #find name include BẢN TIN in Name\n",
    "    df = df[df['Name'].str.lower().str.contains('tin')]\n",
    "    #replace / with - in Name\n",
    "    df['Name'] = df['Name'].str.replace('/','-')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.genco3.com/quan-he-nha-dau-tu/ban-tin-nha-dau-tu.html?y=2024'\n",
    "df = get_pdf_PGV(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.genco3.com/data/files/20240522/638519722466716673_0.pdf'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pdf to C:/Users/hoang.nguyennhat/Desktop/IR/PGV\n",
    "for i in tnrange(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open('C:/Users/hoang.nguyennhat/Desktop/IR/PGV/'+str(df['Name'].iloc[i])+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the file in C:/Users/hoang.nguyennhat/Desktop/IR/PGV to format YYYY-mm, for example 'BẢN TIN NHÀ ĐẦU TƯ THÁNG 01 NĂM 2020' to '2020-01-PGV'\n",
    "files = os.listdir('C:/Users/hoang.nguyennhat/Desktop/IR/PGV/')\n",
    "a = [x.split('NĂM ')[1].split(' ')[0] for x in files]\n",
    "a = [pd.to_datetime(x).strftime('%Y-%m') for x in a]\n",
    "for i in range(len(files)):\n",
    "    os.rename('C:/Users/hoang.nguyennhat/Desktop/IR/PGV/'+files[i],'C:/Users/hoang.nguyennhat/Desktop/IR/PGV/'+a[i]+'-PGV.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MWG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_MWG(x,i):\n",
    "    payload = {'langID': 'vi-VN','cateID': i}\n",
    "    response = requests.get(x, params=payload)\n",
    "    response = response.json()['result']\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    titles = []\n",
    "    pdfs = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href').endswith('.pdf'):\n",
    "            pdf = link.get('href')\n",
    "            pdfs.append(pdf)\n",
    "            #get title from link text, remove blank space and \\n\n",
    "            title = link.text.replace('\\n','').strip()\n",
    "            titles.append(title)\n",
    "    #create dataframe from title and pdf\n",
    "    df = pd.DataFrame({'Title':titles, 'PDF':pdfs})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_cateID:\n\u001b[0;32m      5\u001b[0m     a \u001b[38;5;241m=\u001b[39m url\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m----> 6\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mget_link_MWG\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df,x])\n\u001b[0;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m, in \u001b[0;36mget_link_MWG\u001b[1;34m(x, i)\u001b[0m\n\u001b[0;32m      2\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlangID\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvi-VN\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcateID\u001b[39m\u001b[38;5;124m'\u001b[39m: i}\n\u001b[0;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(x, params\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m titles \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "list_cateID = [193,185,106,98,5,6,28,27,26,25]\n",
    "url = 'https://mwg.vn/Category/GetReportByYear?langID=vi-VN&cateID='\n",
    "df = pd.DataFrame()\n",
    "for i in list_cateID:\n",
    "    a = url+str(i)\n",
    "    x = get_link_MWG(a,i)\n",
    "    df = pd.concat([df,x])\n",
    "df['Title'] = df['Title'].str.replace('|','-')\n",
    "df['Title'] = df['Title'].str.replace('/','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude 'Báo cáo tài chính', 'Báo cáo quản trị', 'Báo cáo thường niên' from Title lowercase\n",
    "df = df[~df['Title'].str.lower().str.contains('báo cáo tài chính')]\n",
    "df = df[~df['Title'].str.lower().str.contains('báo cáo quản trị')]\n",
    "df = df[~df['Title'].str.lower().str.contains('báo cáo thường niên')]\n",
    "#get desktop path\n",
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to C:/Users/hoang.nguyennhat/Desktop/IR/MWG/VI with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/MWG/VI/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/MWG/VI/')\n",
    "#select the character before .pdf in files\n",
    "a = [x.split('.pdf')[0] for x in files]\n",
    "#select last word of a, and move it to the beginning of the string\n",
    "a = [x.split(' ')[-1]+'-'+x+'.pdf' for x in a]\n",
    "a = [x.replace('1-2','2').replace('2-2','2').replace('3-2','2').replace('4-2','2').replace('năm -','2023') for x in a]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/MWG/VI/'+files[i],desktop+'/data/IR/IR/MWG/VI/'+a[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EN\n",
    "list_cateID = [196,188,110,101,65,66,67,68]\n",
    "url = 'https://mwg.vn/Category/GetReportByYear?langID=en-US&cateID='\n",
    "df = pd.DataFrame()\n",
    "for i in list_cateID:\n",
    "    a = url+str(i)\n",
    "    x = get_link_MWG(a,i)\n",
    "    df = pd.concat([df,x])\n",
    "df['Title'] = df['Title'].str.replace('|','-')\n",
    "df['Title'] = df['Title'].str.replace('/','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Title'].str.lower().str.contains('fs')]\n",
    "df = df[~df['Title'].str.lower().str.contains('governance')]\n",
    "df = df[~df['Title'].str.lower().str.contains('sustainability')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to C:/Users/hoang.nguyennhat/Desktop/IR/MWG/VI with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/MWG/EN/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. VJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ir.vietjetair.com/Home/Menu/ban-tin-nha-dau-tu'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#find all pdf links in soup\n",
    "pdfs = []\n",
    "title = []\n",
    "base_url = 'https://ir.vietjetair.com'\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('href').endswith('.pdf'):\n",
    "        pdfs.append(link.get('href'))\n",
    "        title.append(link.text)\n",
    "#convert pdfs to dataframe\n",
    "df = pd.DataFrame({'PDF':pdfs, 'Title':title})\n",
    "df['PDF'] = base_url+df['PDF']\n",
    "df['Title'] = df['Title'].str.replace('/','-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to desktop/data/IR/IR/VJC with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/VJC/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/VJC/')\n",
    "#select the last 4 character before .pdf\n",
    "a = [x[-8:-4] for x in files]\n",
    "#select the 2 character after tháng\n",
    "b = [x.lower().split('tháng ')[1][:2] for x in files]\n",
    "#select a and b and move it to the beginning of the string\n",
    "a = [x+'-'+y+'-'+'VJC'+'.pdf' for x,y in zip(a,b)]\n",
    "#replace 1--,2--,3--,4--,5--,6--,7--,8--,9-- with 01-,02-,03-,04-,05-,06-,07-,08-,09-\n",
    "a = [x.replace('1--','01-').replace('2--','02-').replace('3--','03-').replace('4--','04-').replace('5--','05-').replace('6--','06-').replace('7--','07-').replace('8--','08-').replace('9--','09-') for x in a]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/VJC/'+files[i],desktop+'/data/IR/IR/VJC/'+a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://investor.vietinbank.vn/OtherDocuments.aspx'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "pdfs = []\n",
    "titles = []\n",
    "tr = soup.find_all('tr')\n",
    "for i in tr:\n",
    "    #find a in tr\n",
    "    a = i.find_all('a')\n",
    "    for j in a:\n",
    "        #select the string include 'bản tin' in j.text\n",
    "        if 'bản tin' in j.text.lower():\n",
    "            #get pdf link from j\n",
    "            pdf = j.get('href')\n",
    "            #get title from j.text\n",
    "            title = j.text\n",
    "            #add pdf and title to list\n",
    "            pdfs.append(pdf)\n",
    "            titles.append(title)\n",
    "#convert pdfs and titles to dataframe\n",
    "df = pd.DataFrame({'PDF':pdfs, 'Title':titles})\n",
    "df['PDF'] = 'https://investor.vietinbank.vn/'+df['PDF']\n",
    "df['Title'] = df['Title'].str.replace('/','-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://investor.vietinbank.vn//Handlers/ViewReport.ashx?ReportID=1054\n",
      "https://investor.vietinbank.vn//Handlers/ViewReport.ashx?ReportID=963\n",
      "https://investor.vietinbank.vn//Handlers/ViewReport.ashx?ReportID=997\n",
      "https://investor.vietinbank.vn//Handlers/ViewReport.ashx?ReportID=963\n"
     ]
    }
   ],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to desktop/data/IR/IR/CTG with Title as file name\n",
    "for i in range(len(df)):\n",
    "    # try with time out 20s\n",
    "    try:\n",
    "        response = requests.get(df['PDF'].iloc[i],timeout=20)\n",
    "        with open(desktop+'/data/IR/IR/CTG/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    except:\n",
    "        print(df['PDF'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/CTG/')\n",
    "#select the string after tháng and before .pdf in files, remove blank space\n",
    "a = [x.lower().split('tháng ')[1].split('.pdf')[0].strip() for x in files]\n",
    "a = [x[-4:]+'-'+x.split('-')[0]+'-CTG.pdf' for x in a]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/CTG/'+files[i],desktop+'/data/IR/IR/CTG/'+a[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. PDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_PDR(i):\n",
    "    x = 'https://www.phatdat.com.vn/ban-tin-ir/?no='+str(i)\n",
    "    payload = {'no': i}\n",
    "    response = requests.get(x, params=payload)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pdfs = []\n",
    "    titles = []\n",
    "    #find all class = 'item' in soup\n",
    "    for link in soup.find_all('div', class_='item'):\n",
    "        for a in link.find_all('a'):\n",
    "            pdf=(a.get('href'))\n",
    "            pdfs.append(pdf)\n",
    "            title=(link.find('h6', class_='title-report').text)\n",
    "            titles.append(title)\n",
    "    #convert pdfs and titles to dataframe\n",
    "    df = pd.DataFrame({'PDF':pdfs, 'Title':titles})\n",
    "    df['Title'] = df['Title'].str.replace('/','-')\n",
    "    return df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    a = get_pdf_PDR(i)\n",
    "    df = pd.concat([df,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pdf to desktop/data/IR/IR/PDR with Title as file name\n",
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/PDR/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/PDR/')\n",
    "b = [x.replace('Bản tin IR Quý','').strip() for x in files]\n",
    "#select the last 4 character of b, put it in the beginning of the string\n",
    "b = [x[-8:-4]+'-Q'+x[0]+'.pdf' for x in b]\n",
    "#rename the file in files with list b\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/PDR/'+files[i],desktop+'/data/IR/IR/PDR/'+b[i]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. DIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_DIG(i):\n",
    "    url = 'https://www.dic.vn/ban-tin-nha-dau-tu?page='+str(i)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    link = []\n",
    "    titles = []\n",
    "    \n",
    "    #find div class = 'intro intro1' in soup\n",
    "    for i in soup.find_all('div', class_='intro intro1'):\n",
    "        #find a in i\n",
    "        for j in i.find_all('a'):\n",
    "            #get link from j\n",
    "            link.append(j.get('href'))\n",
    "            #get title from class = 'title' in i\n",
    "            titles.append(i.find('a', class_='title').text)\n",
    "    #convert link and titles to dataframe\n",
    "    df = pd.DataFrame({'Title':titles,'Link':link})\n",
    "    df['Link'] = 'https://www.dic.vn/'+df['Link']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1,22):\n",
    "    a = get_link_DIG(i)\n",
    "    df = pd.concat([df,a])\n",
    "df = df[df['Title'].str.lower().str.contains('ir')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PDF'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PDF'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#get pdf link from link\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m base_url\u001b[38;5;241m+\u001b[39m(link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPDF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PDF'"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    response = requests.get(df['Link'].iloc[i])\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    base_url = 'https://www.dic.vn/'\n",
    "    #find all a in soup\n",
    "    for link in soup.find_all('a'):\n",
    "        #select the string include 'pdf' in link\n",
    "        if 'pdf' in link.get('href'):\n",
    "            #get pdf link from link\n",
    "            x = base_url+(link.get('href'))\n",
    "            df['PDF'].iloc[i] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to desktop/data/IR/IR/DIG with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/DIG/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/DIG/')\n",
    "#select the last 4 character before .pdf in files\n",
    "a = [x[-8:-4] for x in files]\n",
    "#select the 2 character after IR\n",
    "b = [x.lower().split('ir')[1][:3].strip().upper() for x in files]\n",
    "#rename a and b and move it to the beginning of the string\n",
    "a = [x+'-'+y+'-DIG.pdf' for x,y in zip(a,b)]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/DIG/'+files[i],desktop+'/data/IR/IR/DIG/'+a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. DPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_DPM(i):\n",
    "    url = 'https://dpm.vn/category/ban-tin-nha-dau-tu/page/'+str(i)\n",
    "    response = requests.get(url, verify=False)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    link = []\n",
    "    titles = []\n",
    "    #find all h3 in soup\n",
    "    for i in soup.find_all('h3'):\n",
    "        #find a in i\n",
    "        for j in i.find_all('a'):\n",
    "            #get link from j\n",
    "            link.append(j.get('href'))\n",
    "            #get title from j\n",
    "            titles.append(j.text)\n",
    "    #convert link and titles to dataframe\n",
    "    df = pd.DataFrame({'Title':titles,'Link':link})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    a = get_link_DPM(i)\n",
    "    df = pd.concat([df,a])\n",
    "df['PDF'] = 'NAN'\n",
    "df['Title'] = df['Title'].str.replace('/','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    response = requests.get(df['Link'].iloc[i], verify=False)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find all a in soup\n",
    "    for link in soup.find_all('a'):\n",
    "        #select the string include 'pdf' in link\n",
    "        if 'pdf' in link.get('href'):\n",
    "            df['PDF'].iloc[i] = link.get('href')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP PAVILION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dpm.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#save pdf to desktop/data/IR/IR/DPM with Title as file name\n",
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i],verify=False)\n",
    "    with open(desktop+'/data/IR/IR/DPM/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/DPM/')\n",
    "#select the last 4 character before .pdf in files\n",
    "a = [x[-8:-4] for x in files]\n",
    "#extract all number in the string\n",
    "b = [x[:-8] for x in files]\n",
    "#replace I with 1, II with 2, III with 3, IV with 4\n",
    "b = [x.replace('I năm','1 năm').replace('II năm','2 năm').replace('III năm','3 năm').replace('IV năm','4') for x in b]\n",
    "#extract all number from b using regular expression\n",
    "import re\n",
    "b = [re.findall(r'\\d+', x) for x in b]\n",
    "#convert b to string\n",
    "b = [''.join(x) for x in b]\n",
    "#rename the file in files with list a and b\n",
    "a = [x+'-Q'+y+'-DPM.pdf' for x,y in zip(a,b)]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/DPM/'+files[i],desktop+'/data/IR/IR/DPM/'+a[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. GAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_GAS(i):\n",
    "    url = 'https://www.pvgas.com.vn/DesktopModules/EasyDNNnews/ListContentHtml.ashx?portalId=0&moduleId=1514&tabId=153&contentKey=-1&contentPage='+str(i)+'&getPaginationMeta=false&_=1709751847694'\n",
    "    response = requests.get(url)\n",
    "    response = response.json()\n",
    "    soup = BeautifulSoup(response['contentHtml'], 'html.parser')\n",
    "    #find all a in soup\n",
    "    links = []\n",
    "    titles = []\n",
    "    for link in soup.find_all('div', class_='row'):\n",
    "        #find a in link\n",
    "        for a in link.find_all('a'):\n",
    "            if 'https' in a.get('href'):\n",
    "                links.append(a.get('href'))\n",
    "                titles.append(a.text.replace('\\n','').strip())\n",
    "    #convert pdfs and titles to dataframe\n",
    "    df = pd.DataFrame({'Title':titles,'Link':links})\n",
    "    df['Title'] = df['Title'].str.replace('/','-')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    a = get_link_GAS(i)\n",
    "    df = pd.concat([df,a])\n",
    "df['PDF'] = 'NAN'\n",
    "df['Title'] = df['Title'].str.replace('/','-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP PAVILION\\AppData\\Local\\Temp\\ipykernel_30044\\2825293060.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PDF'].iloc[i] = pdf_link\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    response = requests.get(df['Link'].iloc[i])\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    base_url = 'https://www.pvgas.com.vn/'\n",
    "    #find li in soup with class = 'edn_docType_pdf'\n",
    "    for link in soup.find_all('li', class_='edn_docType_pdf'):\n",
    "        #find a in link\n",
    "        for a in link.find_all('a'):\n",
    "            #get pdf link from a\n",
    "            pdf_link = base_url+a.get('href')\n",
    "            df['PDF'].iloc[i] = pdf_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to desktop/data/IR/IR/GAS with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/GAS/'+df['Title'].iloc[i]+'.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\HP PAVILION\\\\Desktop/data/IR/IR/GAS/Bản tin nhà đầu tư Quý II- 2020.pdf' -> 'C:\\\\Users\\\\HP PAVILION\\\\Desktop/data/IR/IR/GAS/2020-Q1-GAS.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#rename the file in files with list a\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files)):\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesktop\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/IR/IR/GAS/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdesktop\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/IR/IR/GAS/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\HP PAVILION\\\\Desktop/data/IR/IR/GAS/Bản tin nhà đầu tư Quý II- 2020.pdf' -> 'C:\\\\Users\\\\HP PAVILION\\\\Desktop/data/IR/IR/GAS/2020-Q1-GAS.pdf'"
     ]
    }
   ],
   "source": [
    "files = os.listdir(desktop+'/data/IR/IR/GAS/')\n",
    "#select the last 4 character before .pdf in files\n",
    "a = [x[-8:-4] for x in files]\n",
    "b = [x[:-8] for x in files]\n",
    "#replace I with 1, II with 2, III with 3, IV with 4\n",
    "b = [x.replace('I-','1-').replace('II-','2-').replace('III-','3-').replace('IV-','4') for x in b]\n",
    "#extract all number from b using regular expression\n",
    "import re\n",
    "b = [re.findall(r'\\d+', x) for x in b]\n",
    "#convert b to string\n",
    "b = [''.join(x) for x in b]\n",
    "#rename the file in files with list a and b\n",
    "a = [x+'-Q'+y+'-GAS.pdf' for x,y in zip(a,b)]\n",
    "#rename the file in files with list a\n",
    "for i in range(len(files)):\n",
    "    os.rename(desktop+'/data/IR/IR/GAS/'+files[i],desktop+'/data/IR/IR/GAS/'+a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. PNJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>https://cdn.pnj.io/images/quan-he-co-dong/2024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   PDF\n",
       "0    https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "1    https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "2    https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "3    https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "4    https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "..                                                 ...\n",
       "104  https://cdn.pnj.io/images/quan-he-co-dong/2022...\n",
       "105  https://cdn.pnj.io/images/quan-he-co-dong/2022...\n",
       "106  https://cdn.pnj.io/images/quan-he-co-dong/2022...\n",
       "107  https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "108  https://cdn.pnj.io/images/quan-he-co-dong/2024...\n",
       "\n",
       "[109 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.pnj.com.vn/quan-he-co-dong/bao-cao-thang/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "pdfs = []\n",
    "#find all a in soup\n",
    "for link in soup.find_all('a'):\n",
    "    #select the string include 'pdf' in link\n",
    "    if 'pdf' in link.get('href'):\n",
    "        #get pdf link from link\n",
    "        pdf = link.get('href')\n",
    "        pdfs.append(pdf)\n",
    "    \n",
    "#convert pdfs and titles to dataframe\n",
    "df = pd.DataFrame({'PDF':pdfs})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get last path after / in pdfs\n",
    "df['Title'] = [x.split('/')[-1] for x in df['PDF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "#save pdf to desktop/data/IR/IR/PNJ with Title as file name\n",
    "for i in range(len(df)):\n",
    "    response = requests.get(df['PDF'].iloc[i])\n",
    "    with open(desktop+'/data/IR/IR/PNJ/'+df['Title'].iloc[i], 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content-Type': 'application/pdf', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Date': 'Wed, 06 Mar 2024 20:02:17 GMT', 'Last-Modified': 'Wed, 21 Feb 2024 01:08:29 GMT', 'ETag': 'W/\"97442bdcb722e24787bb7c1ac7e49b5b\"', 'x-amz-server-side-encryption': 'AES256', 'x-amz-version-id': 'XZDNmmBNLM8HpON33SDfWdoSrlkURNKf', 'Server': 'AmazonS3', 'Content-Encoding': 'gzip', 'Vary': 'Accept-Encoding, Origin', 'X-Cache': 'Hit from cloudfront', 'Via': '1.1 d3fa3a50f1efd848dd27deb9ea2f30e0.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'HAN50-P2', 'X-Amz-Cf-Id': 'cRXmu4xzcPNJ44_pMfPkQXjfSKXYlLXyWtsDc3DcKz-lwTwLpc8YQw==', 'Age': '32'}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(df['PDF'].iloc[i])\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
